{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc07d501-9ea8-4ac5-a116-5730cece6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67fdae33-0b5b-4765-b609-2952d00f5f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iGABA_post\n",
      "mTeSR    85756\n",
      "Name: Basal_media, dtype: int64\n",
      "iGABA_pre\n",
      "N2B27_2Si        80751\n",
      "N2B27_SB_CHIR    40278\n",
      "NIM              18682\n",
      "Name: Basal_media, dtype: int64\n",
      "iGlut_post\n",
      "mTeSR    184431\n",
      "Name: Basal_media, dtype: int64\n",
      "iGlut_pre\n",
      "N2B27_2Si        114780\n",
      "NIM              108104\n",
      "N2B27_SB_CHIR     82028\n",
      "Name: Basal_media, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for sample in ['iGABA_post','iGABA_pre','iGlut_post','iGlut_pre']:\n",
    "    meta = pd.read_csv(\"scanpy/\"+sample+\"_dr_clustered_raw_merged_meta.tsv\",sep=\"\\t\",index_col=0)\n",
    "    meta['M_CycA'] = meta['CycA']\n",
    "    meta.drop('CycA',axis=1,inplace=True)\n",
    "    meta.head()\n",
    "\n",
    "    meta['condition'] = meta['AP_axis'] + \"_\" + meta['DV_axis']\n",
    "    print(sample)\n",
    "    print(meta['Basal_media'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40580b39-9fcf-4f46-99c7-f7c59f2d4c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iGlut_post\n",
      "Basal Media: mTeSR\n",
      "Sample: iGlut_post, Basal Media: mTeSR, Avg R²: 0.3423, Avg MSE: 0.0820, Avg Spearman: 0.6082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# Define k-fold cross-validator\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Placeholder for storing results\n",
    "results = []\n",
    "\n",
    "# Iterate through samples\n",
    "for sample in ['iGlut_post']:\n",
    "    print(sample)\n",
    "    \n",
    "    # Load metadata and expression data (same as before)\n",
    "    meta = pd.read_csv(\"scanpy/\"+sample+\"_dr_clustered_raw_merged_meta.tsv\", sep=\"\\t\", index_col=0)\n",
    "    meta['M_CycA'] = meta['CycA']\n",
    "    adata = sc.read_h5ad(\"scanpy/\"+sample+\"_dr_clustered_raw_merged.h5ad\")\n",
    "    adata.obs['BC'] = adata.obs.index\n",
    "\n",
    "    for BM in set(meta['Basal_media']):\n",
    "        print(f\"Basal Media: {BM}\")\n",
    "        meta_bm = meta.loc[meta['Basal_media'] == BM].copy()\n",
    "        meta_bm['condition'] = meta_bm['AP_axis'] + \"_\" + meta_bm['DV_axis']\n",
    "        \n",
    "        # Only keep conditions with at least 250 cells\n",
    "        conditions_min250 = meta_bm['condition'].value_counts()[meta_bm['condition'].value_counts() > 250].index\n",
    "        meta_bm = meta_bm[meta_bm['condition'].isin(conditions_min250)]\n",
    "\n",
    "        # Find minimal number of cells per condition\n",
    "        min_cells_condition = meta_bm['condition'].value_counts().min()\n",
    "\n",
    "        # Sample cells per condition\n",
    "        meta_bm_sampled = meta_bm.groupby('condition').sample(n=min_cells_condition, random_state=42)\n",
    "\n",
    "        # Get expression data for sampled cells\n",
    "        adata_subset = adata[meta_bm_sampled.index, :].copy()\n",
    "        dgem = pd.DataFrame.sparse.from_spmatrix(adata_subset.X, index=adata_subset.obs.index, columns=adata_subset.var_names)\n",
    "        \n",
    "        # Morphogens and preprocessing (same as before)\n",
    "        morphogens = ['M_'+x for x in ['XAV','CHIR','RA','FGF8','BMP4','SHH','CycA']]\n",
    "        morph_sum = meta_bm_sampled[morphogens].sum()\n",
    "        morphogens = list(morph_sum[morph_sum > 0].index)\n",
    "\n",
    "        # Normalize data (log and min-max normalization)\n",
    "        y = np.log10(meta_bm_sampled[morphogens] + 1).fillna(0)\n",
    "        for morph in morphogens: \n",
    "            y[morph] = (y[morph] - y[morph].min()) / (y[morph].max() - y[morph].min())\n",
    "\n",
    "        # Cross-validation\n",
    "        X = dgem\n",
    "        y_values = y.values\n",
    "\n",
    "        fold_results = []\n",
    "        for fold_idx, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y_values[train_index], y_values[test_index]\n",
    "\n",
    "            # Train RandomForestRegressor with MultiOutputRegressor\n",
    "            regr = RandomForestRegressor(random_state=42, n_jobs=20, n_estimators=100, max_features='sqrt', max_depth=10)\n",
    "            regr_multi = MultiOutputRegressor(regr, n_jobs=4).fit(X_train, y_train)\n",
    "\n",
    "            # Predict on test set\n",
    "            y_pred = regr_multi.predict(X_test)\n",
    "\n",
    "            # Calculate Spearman correlation for each morphogen\n",
    "            spearman_corrs = []\n",
    "            for i, morph in enumerate(morphogens):\n",
    "                corr, _ = spearmanr(y_test[:, i], y_pred[:, i])\n",
    "                spearman_corrs.append(corr)\n",
    "\n",
    "            # Calculate average Spearman correlation, R² score, and MSE\n",
    "            fold_score = {\n",
    "                'r2_score': r2_score(y_test, y_pred, multioutput='uniform_average'),\n",
    "                'mse': mean_squared_error(y_test, y_pred),\n",
    "                'avg_spearman': np.mean(spearman_corrs)\n",
    "            }\n",
    "            fold_results.append(fold_score)\n",
    "\n",
    "            # Generate plots\n",
    "            y_pred_df = pd.DataFrame(y_pred, index=X_test.index, columns=[morph + '_pred' for morph in morphogens])\n",
    "            y_test_df = pd.DataFrame(y_test, index=X_test.index, columns=morphogens)\n",
    "            comb = pd.concat([y_test_df, y_pred_df], axis=1)\n",
    "\n",
    "            for morph in morphogens:\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                sns.boxplot(data=comb, x=morph, y=morph + '_pred')\n",
    "                plt.ylabel('Predicted concentration (A.U.)', fontsize=20)\n",
    "                plt.xlabel('Real concentration (A.U.)', fontsize=20)\n",
    "                plt.title(f\"{morph} - Fold {fold_idx}\", fontsize=22)\n",
    "                plt.xticks(fontsize=18)\n",
    "                plt.yticks(fontsize=18)\n",
    "                \n",
    "                # Create directories if not exist\n",
    "                os.makedirs(f\"figures/multiregressor_validate/{sample}\", exist_ok=True)\n",
    "                \n",
    "                plt.savefig(f\"figures/multiregressor_validate/{sample}/subsampled_multi_v1_BM_{morph}_{BM}_test_fold_{fold_idx}.png\", dpi=350, bbox_inches='tight', pad_inches=0)\n",
    "                plt.close()\n",
    "\n",
    "            # Save model\n",
    "            filename = f\"figures/multiregressor_validate/{sample}/{BM}_fold_{fold_idx}.p\"\n",
    "            with open(filename, 'wb') as filehandler:\n",
    "                pickle.dump(regr_multi, filehandler)\n",
    "\n",
    "            # Save test data\n",
    "            comb.to_csv(f\"figures/multiregressor_validate/{sample}/subsampled_multi_v1_BM_test_{BM}_fold_{fold_idx}.tsv\", sep='\\t')\n",
    "\n",
    "            # Predict and save training data\n",
    "            y_train_pred = regr_multi.predict(X_train)\n",
    "            y_train_pred_df = pd.DataFrame(y_train_pred, index=X_train.index, columns=[morph + '_pred' for morph in morphogens])\n",
    "            comb_train = pd.concat([pd.DataFrame(y_train, index=X_train.index, columns=morphogens), y_train_pred_df], axis=1)\n",
    "            comb_train.to_csv(f\"figures/multiregressor_validate/{sample}/subsampled_multi_v1_BM_train_{BM}_fold_{fold_idx}.tsv\", sep='\\t')\n",
    "\n",
    "        # Append average fold scores for each basal media\n",
    "        results.append({\n",
    "            'sample': sample,\n",
    "            'basal_media': BM,\n",
    "            'avg_r2_score': np.mean([res['r2_score'] for res in fold_results]),\n",
    "            'avg_mse': np.mean([res['mse'] for res in fold_results]),\n",
    "            'avg_spearman': np.mean([res['avg_spearman'] for res in fold_results])\n",
    "        })\n",
    "\n",
    "# Results\n",
    "for result in results:\n",
    "    print(f\"Sample: {result['sample']}, Basal Media: {result['basal_media']}, Avg R²: {result['avg_r2_score']:.4f}, Avg MSE: {result['avg_mse']:.4f}, Avg Spearman: {result['avg_spearman']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6921129-ef0d-4055-aff0-f5a0b446dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {}\n",
    "color_dict['M_SHH'] = ['w',\"#C2D9F7\", \"#98C1F0\", \"#4782DD\", \"#1D52A1\"]\n",
    "color_dict['M_RA'] = ['w', \"#aadce0\",\"#72bcd5\", \"#528fad\", \"#376795\"]\n",
    "color_dict['M_BMP4'] = ['w', \"#ffe6b7\", \"#ffd353\",\"#ffb242\"]\n",
    "color_dict['M_XAV'] = ['w', \"#f9b4c9\",\"#d8527c\",\"#9a133d\"]\n",
    "color_dict['M_CHIR'] = ['w',\"#dec5da\", \"#b695bc\", \"#90719f\", \"#574571\"]\n",
    "color_dict['M_FGF8'] = ['w','#ffbbff','#ee7ae9','#b452cd','#8b008b']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31d842f2-83f7-4de5-b442-da7415df7c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iGlut_post\n",
      "mTeSR\n",
      "figures/multiregressor_validate/iGlut_post/subsampled_multi_v1_BM_test_mTeSR_fold_0.tsv\n",
      "figures/multiregressor_validate/iGlut_post/subsampled_multi_v1_BM_train_mTeSR_fold_0.tsv\n",
      "figures/multiregressor_validate/iGlut_post/subsampled_multi_v1_BM_test_mTeSR_fold_1.tsv\n",
      "figures/multiregressor_validate/iGlut_post/subsampled_multi_v1_BM_train_mTeSR_fold_1.tsv\n",
      "figures/multiregressor_validate/iGlut_post/subsampled_multi_v1_BM_test_mTeSR_fold_2.tsv\n",
      "figures/multiregressor_validate/iGlut_post/subsampled_multi_v1_BM_train_mTeSR_fold_2.tsv\n",
      "figures/multiregressor_validate/iGlut_post/subsampled_multi_v1_BM_test_mTeSR_fold_3.tsv\n",
      "figures/multiregressor_validate/iGlut_post/subsampled_multi_v1_BM_train_mTeSR_fold_3.tsv\n",
      "figures/multiregressor_validate/iGlut_post/subsampled_multi_v1_BM_test_mTeSR_fold_4.tsv\n",
      "figures/multiregressor_validate/iGlut_post/subsampled_multi_v1_BM_train_mTeSR_fold_4.tsv\n"
     ]
    }
   ],
   "source": [
    "for sample in ['iGlut_post']:\n",
    "    print(sample)\n",
    "    for BM in ['mTeSR']:\n",
    "        print(BM)\n",
    "        for fold_idx in [0,1,2,3,4]:\n",
    "            file_path = f\"figures/multiregressor_validate/{sample}/subsampled_multi_v1_BM_test_{BM}_fold_{fold_idx}.tsv\"\n",
    "            print(file_path)\n",
    "            comb = pd.read_csv(file_path,sep=\"\\t\",index_col=0)\n",
    "            comb['fold_idx'] = fold_idx\n",
    "            if fold_idx == 0:\n",
    "                comb_all = comb\n",
    "            else:\n",
    "                comb_all = pd.concat([comb_all,comb])\n",
    "\n",
    "            file_path = f\"figures/multiregressor_validate/{sample}/subsampled_multi_v1_BM_train_{BM}_fold_{fold_idx}.tsv\"\n",
    "            print(file_path)\n",
    "            comb_train = pd.read_csv(file_path,sep=\"\\t\",index_col=0)\n",
    "            comb_train['fold_idx'] = fold_idx\n",
    "            if fold_idx == 0:\n",
    "                comb_train_all = comb_train\n",
    "            else:\n",
    "                comb_train_all = pd.concat([comb_train_all,comb_train])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "252ef33e-d4b1-4e47-8894-10e42a49e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming df is your dataframe\n",
    "\n",
    "# Columns for which you want to calculate correlation and MSE\n",
    "columns = ['M_XAV', 'M_CHIR', 'M_RA', 'M_FGF8', 'M_BMP4', 'M_SHH']\n",
    "\n",
    "df = comb_all\n",
    "# Group by fold\n",
    "grouped = df.groupby('fold_idx')\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for fold_idx, group in grouped:\n",
    "    fold_results = {'fold_idx': fold_idx}\n",
    "    \n",
    "    for col in columns:\n",
    "        if not 'pred' in col:\n",
    "            # Get the column and its predicted counterpart\n",
    "            col_pred = col + '_pred'\n",
    "            \n",
    "            # Calculate Spearman correlation\n",
    "            spearman_corr, _ = spearmanr(group[col], group[col_pred])\n",
    "            \n",
    "            # Calculate MSE\n",
    "            mse_value = mean_squared_error(group[col], group[col_pred])\n",
    "            \n",
    "            # Store the results\n",
    "            fold_results[f'{col}_spearman'] = spearman_corr\n",
    "            fold_results[f'{col}_mse'] = mse_value\n",
    "    \n",
    "    results.append(fold_results)\n",
    "\n",
    "# Convert results to a dataframe\n",
    "results_df_test = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c27e5a0e-e4de-448e-880f-2ea7a889e352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_idx</th>\n",
       "      <th>M_XAV_spearman</th>\n",
       "      <th>M_XAV_mse</th>\n",
       "      <th>M_CHIR_spearman</th>\n",
       "      <th>M_CHIR_mse</th>\n",
       "      <th>M_RA_spearman</th>\n",
       "      <th>M_RA_mse</th>\n",
       "      <th>M_FGF8_spearman</th>\n",
       "      <th>M_FGF8_mse</th>\n",
       "      <th>M_BMP4_spearman</th>\n",
       "      <th>M_BMP4_mse</th>\n",
       "      <th>M_SHH_spearman</th>\n",
       "      <th>M_SHH_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.358927</td>\n",
       "      <td>0.031468</td>\n",
       "      <td>0.789688</td>\n",
       "      <td>0.124228</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.036110</td>\n",
       "      <td>0.599767</td>\n",
       "      <td>0.101874</td>\n",
       "      <td>0.844572</td>\n",
       "      <td>0.051871</td>\n",
       "      <td>0.757717</td>\n",
       "      <td>0.086336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.359188</td>\n",
       "      <td>0.031016</td>\n",
       "      <td>0.793681</td>\n",
       "      <td>0.123785</td>\n",
       "      <td>0.737793</td>\n",
       "      <td>0.036663</td>\n",
       "      <td>0.597810</td>\n",
       "      <td>0.103042</td>\n",
       "      <td>0.844956</td>\n",
       "      <td>0.051350</td>\n",
       "      <td>0.762145</td>\n",
       "      <td>0.086002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.357212</td>\n",
       "      <td>0.031531</td>\n",
       "      <td>0.792309</td>\n",
       "      <td>0.125030</td>\n",
       "      <td>0.738091</td>\n",
       "      <td>0.036332</td>\n",
       "      <td>0.598050</td>\n",
       "      <td>0.101935</td>\n",
       "      <td>0.845873</td>\n",
       "      <td>0.051162</td>\n",
       "      <td>0.755958</td>\n",
       "      <td>0.086329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.355672</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>0.792486</td>\n",
       "      <td>0.124245</td>\n",
       "      <td>0.739178</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.595519</td>\n",
       "      <td>0.101713</td>\n",
       "      <td>0.845572</td>\n",
       "      <td>0.050067</td>\n",
       "      <td>0.764336</td>\n",
       "      <td>0.085756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.357370</td>\n",
       "      <td>0.031389</td>\n",
       "      <td>0.791565</td>\n",
       "      <td>0.124605</td>\n",
       "      <td>0.738667</td>\n",
       "      <td>0.036138</td>\n",
       "      <td>0.597851</td>\n",
       "      <td>0.101454</td>\n",
       "      <td>0.845146</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.761069</td>\n",
       "      <td>0.085955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_idx  M_XAV_spearman  M_XAV_mse  M_CHIR_spearman  M_CHIR_mse  \\\n",
       "0         0        0.358927   0.031468         0.789688    0.124228   \n",
       "1         1        0.359188   0.031016         0.793681    0.123785   \n",
       "2         2        0.357212   0.031531         0.792309    0.125030   \n",
       "3         3        0.355672   0.031919         0.792486    0.124245   \n",
       "4         4        0.357370   0.031389         0.791565    0.124605   \n",
       "\n",
       "   M_RA_spearman  M_RA_mse  M_FGF8_spearman  M_FGF8_mse  M_BMP4_spearman  \\\n",
       "0       0.734472  0.036110         0.599767    0.101874         0.844572   \n",
       "1       0.737793  0.036663         0.597810    0.103042         0.844956   \n",
       "2       0.738091  0.036332         0.598050    0.101935         0.845873   \n",
       "3       0.739178  0.036810         0.595519    0.101713         0.845572   \n",
       "4       0.738667  0.036138         0.597851    0.101454         0.845146   \n",
       "\n",
       "   M_BMP4_mse  M_SHH_spearman  M_SHH_mse  \n",
       "0    0.051871        0.757717   0.086336  \n",
       "1    0.051350        0.762145   0.086002  \n",
       "2    0.051162        0.755958   0.086329  \n",
       "3    0.050067        0.764336   0.085756  \n",
       "4    0.050600        0.761069   0.085955  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "279ff0e8-2b9a-4cd7-acb9-61e1fa62040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_train.columns = [x+\"_train\" for x in results_df_train.columns]\n",
    "results_df_test.columns = [x+\"_test\" for x in results_df_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bfc2833c-2d6b-40af-8651-ba8ff12c5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_merged = pd.merge(results_df_train,results_df_test,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "427ec188-76aa-4322-be77-fa54894bce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_merged = results_df_merged.drop('fold_idx_train',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79996c02-2b1d-4c06-aa85-be073505ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cols = ['fold_idx_test','M_BMP4_mse_test', 'M_BMP4_mse_train', 'M_BMP4_spearman_test', 'M_BMP4_spearman_train', 'M_CHIR_mse_test', 'M_CHIR_mse_train', 'M_CHIR_spearman_test', 'M_CHIR_spearman_train', 'M_FGF8_mse_test', 'M_FGF8_mse_train', 'M_FGF8_spearman_test', 'M_FGF8_spearman_train', 'M_RA_mse_test', 'M_RA_mse_train', 'M_RA_spearman_test', 'M_RA_spearman_train', 'M_SHH_mse_test', 'M_SHH_mse_train', 'M_SHH_spearman_test', 'M_SHH_spearman_train', 'M_XAV_mse_test', 'M_XAV_mse_train', 'M_XAV_spearman_test', 'M_XAV_spearman_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e95201c-b816-47f6-a9ce-2c306e526b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_merged = results_df_merged[sorted_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb66c709-dda2-4a84-8e47-27505625145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_merged.to_csv(\"figures/multiregressor_validate/training_overview.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2f4b1a7a-2cdb-4beb-a4c0-ff9cdac8085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column_  fold_idx  mse_test  mse_train  spearman_test  spearman_train\n",
      "0   M_BMP4         0  0.059409   0.051871       0.838077        0.844572\n",
      "1   M_BMP4         1  0.057434   0.051350       0.838974        0.844956\n",
      "2   M_BMP4         2  0.057382   0.051162       0.837578        0.845873\n",
      "3   M_BMP4         3  0.058064   0.050067       0.839274        0.845572\n",
      "4   M_BMP4         4  0.057939   0.050600       0.838972        0.845146\n",
      "5   M_CHIR         0  0.143628   0.124228       0.729066        0.789688\n",
      "6   M_CHIR         1  0.142210   0.123785       0.722553        0.793681\n",
      "7   M_CHIR         2  0.143160   0.125030       0.722977        0.792309\n",
      "8   M_CHIR         3  0.145720   0.124245       0.729131        0.792486\n",
      "9   M_CHIR         4  0.143170   0.124605       0.732817        0.791565\n",
      "10  M_FGF8         0  0.117045   0.101874       0.439499        0.599767\n",
      "11  M_FGF8         1  0.113922   0.103042       0.455752        0.597810\n",
      "12  M_FGF8         2  0.115712   0.101935       0.459892        0.598050\n",
      "13  M_FGF8         3  0.118704   0.101713       0.439805        0.595519\n",
      "14  M_FGF8         4  0.119286   0.101454       0.435761        0.597851\n",
      "15    M_RA         0  0.040811   0.036110       0.731432        0.734472\n",
      "16    M_RA         1  0.043682   0.036663       0.734869        0.737793\n",
      "17    M_RA         2  0.040994   0.036332       0.742018        0.738091\n",
      "18    M_RA         3  0.042615   0.036810       0.728798        0.739178\n",
      "19    M_RA         4  0.041258   0.036138       0.731893        0.738667\n",
      "20   M_SHH         0  0.096064   0.086336       0.657883        0.757717\n",
      "21   M_SHH         1  0.096092   0.086002       0.653084        0.762145\n",
      "22   M_SHH         2  0.097284   0.086329       0.649549        0.755958\n",
      "23   M_SHH         3  0.096151   0.085756       0.653349        0.764336\n",
      "24   M_SHH         4  0.096832   0.085955       0.640575        0.761069\n",
      "25   M_XAV         0  0.034746   0.031468       0.243571        0.358927\n",
      "26   M_XAV         1  0.037162   0.031016       0.261834        0.359188\n",
      "27   M_XAV         2  0.035063   0.031531       0.253077        0.357212\n",
      "28   M_XAV         3  0.033821   0.031919       0.267170        0.355672\n",
      "29   M_XAV         4  0.035010   0.031389       0.237948        0.357370\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your dataframe with the structure you provided\n",
    "# First, melt the dataframe to have a long format\n",
    "\n",
    "melted_df = pd.melt(results_df_merged, id_vars=['fold_idx_test'], \n",
    "                    var_name='metric', \n",
    "                    value_name='value')\n",
    "\n",
    "# Extract the actual columns (e.g., M_BMP4) and the metric (e.g., mse/spearman, test/train)\n",
    "melted_df['column'] = melted_df['metric'].str.extract(r'(M_[A-Z0-9]+)')\n",
    "melted_df['metric_type'] = melted_df['metric'].str.extract(r'(mse|spearman)')\n",
    "melted_df['train_test'] = melted_df['metric'].str.extract(r'(train|test)')\n",
    "\n",
    "# Now pivot the table to get the train and test metrics in separate columns\n",
    "reshaped_df = melted_df.pivot_table(index=['column', 'fold_idx_test'], \n",
    "                                    columns=['metric_type', 'train_test'], \n",
    "                                    values='value').reset_index()\n",
    "\n",
    "# Flatten the multi-level columns\n",
    "reshaped_df.columns = ['_'.join(col).strip() for col in reshaped_df.columns.values]\n",
    "\n",
    "# Rename the 'fold_idx_test_' column to 'fold_idx' (optional)\n",
    "reshaped_df.rename(columns={'fold_idx_test_': 'fold_idx'}, inplace=True)\n",
    "\n",
    "print(reshaped_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d60a4-bf87-497e-9695-1189b5f21c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_jjans_3.10_scanpy",
   "language": "python",
   "name": "py_jjans_3.10_scanpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
